# Introduction

Recent advances in small-scale and non-intrusive methods for measuring brain activity have increased the potential for brain-controlled interfaces (BCI) for both the professional medical community all the way to the hobby-driven and DIY communities. Both \href{http://neurosky.com/blog/}{NeuroSky} and \href{https://www.emotiv.com/category/news/}{Emotiv} are driving forces behind the progress of this technology and offer communities dedicated to helping bring together like-minded developers to improve the state-of-the-art approaches as applied to electroencephalography (EEG). \href{https://openbci.com/community/}{OpenBCI} takes a slightly different approach in that they have open-sourced the software and libraries need for interfacing with their system along with the hardware schematics used for building their boards, the \href{https://shop.openbci.com/collections/frontpage/products/pre-order-ganglion-board}{Ganglion} and the \href{https://shop.openbci.com/collections/frontpage/products/cyton-biosensing-board-8-channel}{Cyton}. The hardware limitations may be starting to be addressed. However, interpretation of the generated signals remains a difficult challenge \cite{bib:eeg_class_pr} that is still primarily addressed by leading research labs and large medical facilities.

# Problem Statement

Solving problems in this domain requires teams to be proficient in numerous domains running the gamut from neuroscience to computer science. As such, research towards progressing BCI systems has not matched the pace of the developing potential of the requisite hardware. Rather, many projects and work tends to focus on approaches which focus on gathering signals from specific areas of the brain. Namely, these signals have been used to measure levels of attention and relaxation. In fact, both NeuroSky and Emotiv have proprietary algorithms for transforming signals measured from the prefrontal locations of the international 10-20 system into values which represent how focused or relaxed a user is at a given point in time.

There are several issues with this approach. Arguably the largest is that it focuses work on only a single type of signal. From a theoretical perspective, the region of the brain that is most active when a user is performing some action is dependent on the actual action or activity. For example, the occipital cortex is responsible for processing visual information, while the temporal cortex is active in matters related to speech and natural language \ref{bib:imotions_eeg_basics}. Thus, while researchers and developers have been attempting to solve problems such as correlating signals to language, approaches have often fallen back on clever manipulations of measurements taken from the prefrontal cortex rather than measuring and analyzing signals from the portions of the brain that are primarily responsible for these actions. While certain levels of success can be attained in this manner \ref{bib:opencbi_drone}, it limits the possibilities by which humans may be able to interact with computer systems through thought alone.

A further issue is with regards to a user's ability to manipulate these various states of mind. Various studies have shown that not everyone is equally capable of manipulating their brain patterns in such a way as to be able to effectively use a BCI system. As such, researchers often simply disregard those trials. Furthermore, this tends to be a fairly manual task which involves a high level of expert insight and training. This is, of course, costly both with regards to time as well as personnel, as this expert must dedicate their knowledge towards cleaning the dataset. Unfortunately, this task cannot be crowd-sourced in the same manner as many other data preparation tasks can be, eg. sorting and labeling images of animals, due to the high level of expertise required in understanding the various ways in which EEG signals can be represented. It is required that experts interpret these montages in order to distinguish between relevant event-related potentials and undesired noise and artifacts.

#### Insert image

Take, for example, the transverse bipolar montage in figure \ref{fig:eye_flutter} which depicts eye flutter by a user. This artifact occurs when the user moves their eyes, which induces a changing potential in the frontopolar leads. It would not be reasonable to expect this to be common knowledge which could be easily identified by a non-expert. It has been found that similar types of tasks can be gamified with rather decent results, as was done by MIT in identifying protein folding structures. However, this still requires validation by a subject matter expert in order to verify that the data has been properly cleaned and prepared.

## Motivation

It is likely the case that part of the reason for the field to have advanced in such a manner is due in part to the disparate areas of expertise. That is, an individual or team that is stronger with regards to the cognitive sciences will be able to innovate in the realm of neuroscience, whereas a team stronger in the realm of computer science and artificial intelligence engineering will take approaches which advance the field from the perspectives of classification and data analysis. While this can be somewhat remedied by having a mix of skill-sets within a team, a single team can only grow so large, and there will still inevitably exist a gap in expertise between the domains involved in developing such a complex system.

Based on the aforementioned concern, it would prove fruitful to provide both researchers and hobbyists an intermediary step between the distinct theoretical aspects involved in advancing the capabilities of BCI systems. That is, provide a method for the subject matter experts, in this case, the neuroscientists, to communicate and provide the information and data to the computer scientists in such a manner that it is able to leverage the current state-of-the-art methods for data analysis and classification.

Furthermore, an open problem in the field of cognitive computing is with regards to the forward and inverse problems. That is, researchers are not only trying to understand the effect on the brainwave patterns evoked by different stimuli (the inverse problem), but they are also still trying to determine what causes certain artifacts in EEG readings (the forward problem). Any progress to simplifying the analysis of these problems is thus to the benefit of neuroscientists and the field as a whole.

Finally, neural networks are often cited as being black boxes in the sense that it is difficult to reason as to the how or why certain predictions are made. However, progress is being made to this end, particularly with regards to the domain of image classification. Thus, if the knowledge representation were able to be more closely aligned to the progress currently being made by the field of computer vision, it would offer the ability for the domain of neuroscience to leverage the research currently being undertaken by this field of computer science. In this way, the inner-workings of the brain can be more directly explored and may offer insights as to the forward and inverse problems.

## Thesis Statement

The research towards this thesis will focus on addressing the issue of this domain gap. This involves developing a method for representing the multivariate time-dependent signals collected by an EEG. Additionally, this data representation will be tested in order to verify that it is both able to be intuitively interpreted by subject matter experts as well as by artificial intelligence engineers. Finally, it will be applied to a specific use case where a user will attempt to use their mind in order to move a character through a simple game on a computer.

## Prior Work

As has been alluded to previously, much of the prior work in this field has been a two pronged approach: neuroscientists working to extract meaningful features from the generated signals and computer scientists working to use those features to perform data analysis and classification. The features often rely on common digital processing techniques which are applied to different montages, or methods of representing the signals. For the work done by data scientists, the signals are often viewed as multivariate time series. As such, common classification techniques involve models well-situated to dealing with time-series data, such as recurrent neural networks or logistic regression models.

When approaching the problem of classification of motor imagery events, subject matter experts often perform manual feature extraction \cite{bib:efficient_class_motor_imagery} based on the theoretical underpinnings of the neuroscience involved. Often, these features take the form of Hjorth Parameters \cite{bib:ann_hjorth_params}, Fourier or Laplacian transforms, or wavelet transforms. These features are then fed into machine learning classifiers, such as support vector machines or logistic regression models \cite{bib:nn_log_regr}. However, it is often the case that accuracy is used as a metric of evaluation, although the events are often considered under the oddball paradigm. Another method of evaluation is a transient analysis of the system with regards to the timing involved in recognizing and classifying an event \cite{bib:measuring_vigilant_attention}. In this method of evaluating the performance of classifying event related potentials, the researchers create a plot which shows the start of an event as boundary marks. They then plot where the system made predictions about the onset and end of an event. This then allows the researchers to visually inspect the ability of the model to accurately identify oddball events as well as how long it took for a particular event to be recognized, assuming that the event was successfully recognized by the classifier.

## Objectives

Due to the thesis statement proposing a novel approach for preparing the data in a specified format, it is difficult to assert an outright rejection of the hypothesis. However, it is desired that the system would be able to perform to a level comparable to current state-of-the-art models. Thus, the expected outcome is a comparison against current research models in terms of ability to classify a pre-determined set of events. Furthermore, it should be able to be qualitatively examined in order to allow for experts to directly interpret the data representation to a meaningful extent. The desired outcomes of the proposed system is then both quantitative (with regards to comparison against other classification techniques) and subjective (due to relying on interpretation by a subject matter expert). To this point, the work described hereto will be considered complete following creation of a library to generate and analyze the EEG data representation images along with a comparison of the system's performance against existing models.

# Approach

This effort will require both a hardware and software component. For the hardware, this will be the Ganglion board. OpenBCI develops this board and an open-source library for interfacing with the data stream. For the software, it will be written in Python and will make use of the numerous machine learning and AI libraries provided by the community, such as Keras and Scikit-learn. These tools will be used in the development of a method of representing the signals generated by the Ganglion. The data representation of a single sample will take the form of an image, where each image generated correlates to a series of time samples of the data channels collected by the Ganglion board. Typically, these signals would be fed directly into a machine learning algorithm, such as a recurrent neural network. This method of preparing the data will be compared against other state-of-the-art techniques for performing motor imagery classification.

## Intuition

Teams composed of different areas of expertise will inevitably face an issue of terminology. One domain will use terms and phrases which are either not common-place, or may even be contradictory, to similar terms used by the other domain. Thus, having common phraseology can go a long way in establishing an effective method of communication between the various domain experts. Some teams attempt to solve this problem by having an ever-growing compendium of common terms. However, not only can this quickly become unmanageable, but it still offers the potential for confusion if there happens to be any missing terms. On the other hand, images and graphics tend to be more universally interpreted. That is, the human mind perceives images in a fairly ubiquitous manner in that the mind tends to search for particular features in an image, such as corners, edges, and color splotches. Thus, leveraging this characteristic of how humans perceive visual information would allow the different experts to point more directly to certain properties or artifacts present in the image.

Furthermore, intellect is often seen as an ability to recognize patterns. In fact, this is the basis for intelligence quotient (IQ) quizzes. Performing such a task, however, is not strictly dependent on ones ability to recognize a pattern, but also on how an individual views the information in their mind. For instance, some individuals view mathematical concepts as shapes which fit together in various ways. Viewing numbers in this way can prove beneficial in performing mental arithmetic operations or to extend complex mathematical concepts to new domains. It is based on this insight that representing information in a graphical manner will prove advantageous for machine learning models to learn to classify complex event-related potentials. Rather than relying on expert and human oversight in order to guide the learning capabilities of a model, the model would be able to learn shapes and forms inherent in the data in order to derive insights about how to distinguish between the different classes.

## Data Acquisition

The data used to build out and validate the proposed system and method of data representation will be pulled from existing datasets as well as manually generated through use of an EEG headset. The use of existing datasets allows for a direct comparison against prior research as well as facilitates development of the system due to the fact that many of these datasets have been pre-cleaned or offer a baseline method for cleaning. Furthermore, if there is a statistically significant disparity between the performance of the system on the pre-existing datasets in comparison to the manually collected data, this could signify that the data collected from the EEG headset may have been improperly collected or cleaned.

The manually collected data is a required asset due to the necessity of having a method to collect, in real-time, the signals from a user's brain. Thus, in order to create the actual system which allows a user to control the character in a game, the method of data acquisition is already a requirement. Thus, it can be further leveraged in order to better create and validate not only the models, but also the methods employed for data acquisition and cleaning.

## Data Representation

The meat of the proposed approach comes in the form of creation of the method of representing the data. From a high-level, the data representation has the following requirements.

  - Holds true to the theoretical principles of the underlying data
  - Easily interpreted by both subject matter experts and artificial intelligence engineers
  - Offers classification performance comparable to current state-of-the-art models

In the list of requirements, the first point essentially captures the idea that the data must not be represented in a form that leverages some undesired characteristic that may happen to be present in the dataset. For instance, when a user blinks their eye, a noticeable artifact is produced. However, this artifact is not actually indicative of the desired event. Thus, the data representation must not attempt to use such a feature when attempting to classify between right and left movement.

The second point is the requirement which captures the essence of representing data in this manner. That is, it is meant to bridge the gap between the areas of expertise offered by the neuroscientist domain experts and the skill-set of an artificial intelligence engineer. By requiring that the data be understandable to both sets of research experts, it should allow for a more direct line of communication about how and why the model may be performing as it is. In this way, development of accurate and robust models is simplified and ensures the team is able to communicate more effectively.

The third point ensures that the machine learning model is actually able to use the data in this form in order to accurately classify between the desired types of events. If this were not the case, the proposed method of data representation would serve little purpose beyond being another method for representing the information such as is done by current EEG montages. Furthermore, it stipulates that not only does it perform adequately, but it must be able to keep pace with current, top models. Thus, it is likely that certain parameters will have to be identified which offer tuning of certain parameters used to create the spectogram. One such parameter is expected to be the number of past, discrete data points in a single image. For instance, the effect of a stimulus is not expected to be present for longer than five seconds. Thus, there would be little to no reason to include such a long range of time in identifying a particular event. In fact, it is likely that the period of interest is much shorter than half a second. However, the actual length of time is unknown and is an area which must be explored in order to determine the optimal length of time for motor imagery event detection.

## Classifier Models

Since the mid-80s, several different techniques have been applied in order to distinguish between different events as well as different mental states. However, despite this variability in the specifics, due to the nature of the problem itself, the classifiers are typically derived from a set of parent classification techniques. Furthermore, the classification techniques employed are often representative of the background of the team of the researchers involved. For instance, as previously described, many neuroscience focused teams employ techniques which allow them to leverage their theoretical understanding of the mind. This requires significant effort in performing feature extraction and is better situated to being fed to models such as logistic regression techniques or support vector machines. However, computer science minded teams tend towards classifiers following an artificial neural network architecture due to the ability of these models to perform automatic feature extraction to an extent and, thus, requires less of a deep-dive into the theoretical underpinnings of the neuroscience involved in forming the decision boundaries.

### Logistic Regression

Logistic regression relies primarily on a statistical analysis of the classes involved in a logistic model. That is, it observes the samples, or data points, and attempts to build a function which mathematically represents the samples. In the case of EEG analysis of motor imagery events, each sample is a single, oddball event. Each event is then described by various features, such as entropy or spatial-temporal spectral energy. In this way, each sample can be considered as a set of parameters, and the regression model fits the best hyper-plane to describe those parameters.

This model offers particular benefit to subject matter experts due to the ease of interpretation. As it is based in statistics, a wide number of fields are able to readily understand the method by which this model is able to perform classification, which is a large benefit over certain forms of neural networks which may require more expertise to interpret. Additionally, this type of model explicitly operates on extracted features, thus allowing those same experts to understand the actual information the model is using to perform its predictions.

### Support Vector Machine

Just as with logistic regression, support vector machines operate on a discrete set of features. However, this does not mean that each feature must be discrete, rather it means that the information presented to the model can be used to form a hyper-plane which differentiates between the various classes present in the dataset. In this manner, it offers a similar benefit to subject matter experts in that they are easily understood with respect to how and why they are making their predictions. Furthermore, they offer a benefit over neural networks in that they typically require less information in order to perform adequately for a large number of tasks. This is particularly useful in the task of motor imagery classification as it can cost a significant number of resources to preform a single EEG recording session.

### Convolutional Neural Network

Convolutional neural networks have been shown to perform extremely well in the tasks of computer vision and pattern recognition. Primarily, this is due to the fact that images and patterns can often be interpreted as a discrete or continuous signal. As such, convolution is able to match particular signal forms as well as recognize arbitrarily complex forms in signals. Furthermore, they offer the benefit of operating directly on images rather than requiring manual feature extraction. In addition to training being more automated than models such as logistic regression and support vector machines, these models have the benefit that they are able to recognize latent variables which may be hidden or unknown to human researchers. Unfortunately, this can also obscure reasoning behind why a model makes a particular prediction.

### Recurrent Neural Network

Recurrent neural networks are typically an intuitive choice when dealing with time-related information, such as the stock market or information flows. This is largely due to the fact that they are specifically designed to retain past information for a length of time. For example, in a long short-term memory (LSTM) architecture, a typical cell is comprised of an input gate, an output gate, and a forget gate. These three gates work in conjunction to retain information for an arbitrary length of time based on activation states of the cell. LSTMs specifically were designed to deal with the issue of vanishing and exploding gradients. However, many other RNNs have been specially crafted in order to perform better in a particular domain.

RNNs have the unfortunate characteristic that they are considered difficult to train in the sense that it can take a lot of information in order to properly learn the time-dependent functions which form the decision boundaries of the classifier. To this end, they can be considered more sensitive to spurious or uncleaned data which is often characteristic of EEG signals. Furthermore, it is expected that this classifier model would preform worse when attempting to apply transfer learning. That is, the trained model will likely not be as successful at generalizing to new users even if it is able to generalize to different tasks for a particular user.

## Experiment Setup

This thesis is expected to require three different forms of experiments. The first will be an initial data collection stage where the \sout{victims} volunteers will have their brainwaves monitored and recorded while performing a simple motor imagery task. The second phase of the experiment will be the attempts to represent the data in a meaningful manner and to train the classifiers on the user-generated data. The final phase of the experiment will occur at a separate time and will require the user to attempt to use the system to control an on-screen character using only their mind.

### Phase One

For the data acquisition phase of the experiment, the brainwaves of at least two users will be recorded while performing an motor imagery task. This task will take on the form of attempting to follow the directions presented to them. The information recorded for this will be comprised of the following.

  - The start of an event
  - The end of the event
  - The electrical potentials from each EEG channel during the entire session

In this way, the markers for each trial can be placed in order to determine a set of time-related potentials which should be associated with a particular event. For instance, it is expected that a typical stimulus in the oddball paradigm will take between $150 ms$ and $300 ms$ to be present on an EEG recording. Thus, this many samples following the event will demarcate the start and end of the event boundaries. This will allow for creation of a labeled dataset which can be fed to the classifiers for training.

### Phase Two

The second phase of the experiment will consist of training the classifiers on the generated data. This will require various, high-level steps. The first will be to split the dataset in order to build a training set and a validation set. The second will be an attempt to replicate existing work in order to build a baseline classifier for comparison. To this end, an echo state network will be built, as it has been shown to achieve state-of-the-art performance on event-related potential classification. Furthermore, there exists Python bindings to a C++ library which should facilitate the building of a baseline model.

Following implementation of the baseline model, the data will be represented using the aforementioned transformation in order to generate a spectral image correlating time versus frequency and time versus channel. The actual samples will contain the same numerical information as the previously used samples, and as such, a single image will be produced for each data sample. This will allow for direct transformation of the dataset from a Pandas dataframe into a set of labeled images. These images will be fed into a CNN architecture for the task of classifying the samples. Due to the skew in the class sparsity, accuracy will likely not be an adequate metric of performance. Instead, the model will be evaluated on the basis of timing, precision, and recall.

## Phase Three

The final phase of the experiment will be where the system is tested in a real-world environment. To this end, the same users previously used to collect the training data will attempt to use the built system to control a character on a screen. In order to reduce complexity and ensure that the testing captures the ability of the user to use the system rather than effectively play the game, the game will be a simple 2D maze game with no time dependence on moving the character. In other words, they will not have to carefully control the timing of when the character moves left or right. Rather, it will be a continuous movement back-and-forth. The alternative would be a game such as Snake, where the player must make a specific movement at a specific time in order to collect the rewards for growing the snake.

By structuring the evaluation phase of the experiment in this way, it allows for the system's performance to be measured both in terms of precision and recall, as well as by a timing analysis. The first is done by simply comparing the expected result versus the result of the classification based on the user's input. The timing analysis will be done by marking the start of when a user should start to move a certain direction. The salient feature here would then be the amount of time it takes for the system to detect an attempt to move the character in that direction. An important consideration here occurs in the case where the system misclassifies the motor imagery event, eg, interpreting a left movement as a right movement. In this case, no further timing analysis should occur, as it is likely the case that a user will react and be better able to move a character in a particular direction. For instance, as moving left and right is closely tied to moving the left or right hand, respectively, it is expected that the system will be able to perform faster when the user attempts to move in the direction associated with their dominant hand. As such, there will be a difference in the timings for each direction that will likely be of interest for further analysis and should thus be distinguished between when performing the timing analysis.

## Expected Challenges

As this thesis intends to provide a proof-of-concept of the feasibility of a certain method of classification, it is necessary to develop a system which is capable of recording the EEG signals directly from a user. To this end, the Ganglion board, created and released by OpenBCI, was selected for use. However, this board presents several challenges when using the released GUI tool meant to collect and display the readings from the channels on the board. For instance, consider figure \ref{fig:openbci_gui}. The tool is configured to display the values streamed from the board along with the Fourier transforms, as provided by the tool itself. However, this information is not directly accessible except for visual analysis. Instead, in order to get it into a form usable for use outside of the OpenBCI environment, the data must be exported in some way or otherwise made accessible as a data stream. This presents a challenge in the fact that the developed library is not particularly stable or robust with regards to its ability to validate data signal strength while streaming the data. Furthermore, its ability to interface with a Windows environment is a known limitation due to the underlying Bluetooth library. However, certain other libraries, such as CUDA, can be more easily configured on Windows. Thus, selecting one platform for development requires sacrificing usability of one library for usability of another.

With regards to the data itself, a common trope in machine learning is that there is no substitute for clean data. This holds particularly true for EEG tasks due to the low signal-to-noise ratio inherent in the data itself, regardless of the method used for collecting the data. Not only can the data be obfuscated by experimental setup, such as electronics in the test environment or use of dry versus wet electrodes, but this can be further confounded upon due to variances in the test subject themselves. EEG data is meant to capture the electrical potentials which occur when a user performs some action which requires use of the brain. Thus, this is inherently dependent on the actual mental state of the user, including hunger, fatigue, and general contentment. Altering any of these states has the potential to be reflected in the EEG recordings when performing the same task. One solution to this issue is to continuously build out a larger and larger dataset which represents the user in various states of mind. However, this quickly becomes intractable due to the exponential growth of adding a single feature to the set of monitored states. That is, for adding a single feature to monitor (hunger, sleep level, happiness, stress, etc), the number of potential mental states grows by a factor proportional to the number of discrete states of the new feature.

# Current Status

The majority of the work to date, beyond initial research and theory development, has been focused on addressing the issue of gathering clean data in a manner which is usable for the purposes of the experiment. For the purposes of gathering clean data, this has taken on two forms: locating clean datasets and building a system for manual data acquisition. As EEG signal analysis and classification is not a new problem, there are numerous datasets in the public domain, released both as part of a competition or by researchers hoping to spur the progress of the field. These include several versions of a dataset used at Neural Information Processing Systems (NIPS) in the early to mid 2000's \cite{bib:nips_datasets} as well as from various Kaggle competitions \cite{bib:kaggle_datasets}. Specifically for the task of motor-imagery classification, a large-scale dataset was released by a team of researchers in an attempt to address the lack of a standard dataset that can be used for the purposes of developing and evaluating approaches to solve the problem of motor-imagery classification \cite{bib:large_motor_imagery_dataset}.

Current work has also involved addressing the difficulties in working with the Ganglion board. The decided upon approach for accessing the data stream was to bypass the GUI tool altogether and communicate directly with the hub the board uses to communicate to the GUI. While this requires additional effort due to requiring that the data acquisition application conforms to the specifications required by the communication hub, this method provides the benefit of a more direct line of communication with the board. Figure \ref{fig:data_samples} shows several data samples received from the Ganglion board that are ready for further processing.

#### Insert images

Additionally, communicating with the board in this way facilitates the ability to do impedance checking. This offers the ability to check the quality of the signal. However, low impedance values do not necessarily guarantee a high signal-to-noise ratio. Instead, it means that the majority of the received signal is from the head of the user rather than from board. Several example samples are shown in figure \ref{fig:impedance_samples}.

The \href{current code}{https://github.com/Adrang/SystemControl} is currently hosted on GitHub. Along with the code, this repository contains a list of papers, links, dissertations, and other theses which may prove beneficial in execution of this thesis. This GitHub account will also serve host to the site to track the ongoing progress of the thesis until completion.

# Next Steps

The focus of this research work is to present a novel approach for representing information in a manner which bridges the gap between subject matter experts and artificial intelligence engineers. Thus, to this end, it would prove worthwhile to develop a library which allows EEG and neuroscience experts to import their data for analysis and to quickly generate the image maps that can be fed to various CNN architectures. Furthermore, as a primary focus of this work is to compare the actual ability of the classifier to act on data represented in this form, it is necessary to provide a proof-of-concept of the system in action. To this end, the system will offer a limited set of controls to a user which allow them to control an virtual game agent in a simple game, such as a maze. Finally, the research conducted and the results obtained will be captured in a detailed report which expresses the theory behind the neuroscience as well as the methods applied that allow data to be represented in such a form as to allow for accurate classification based on current, state-of-the-art machine learning algorithms. Explicitly put, the thesis will deliver the following items.

  - Python library to read in EEG data, provide analysis functionality, and generate image maps of the data to feed to CNN models
  - Proof-of-concept of using CNN classifier along with generated image map data to allow a user to use their mind to play a simple game
  - Technical report on the research conducted and the results obtained

Due to the nature of the work involved in testing the hypothesis and building the anticipated deliverables, the majority of the time is expected to be dedicated to the tasks of data acquisition and analysis. From a high-level perspective, the work for this thesis can be roughly broken down into various tasks, as outlined in Table \ref{tab:thesis_phases}.

However, this is a cursory overview of the general steps involved in performing the research tasks described hereto. Table \ref{tab:time_table} outlines the expected work on a week-by-week basis starting from the start of the Fall 2019 semester to the targeted defense date of the week of December 16th, 2019. 
